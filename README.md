# Hand-Sign-Recognition
  There is an undeniable communication problem between the deaf community and the hearing majority 
which can be solved by using innovation ideas and techniques which can be used to automatically recognise 
sign language and convert it into text. Sign Language is used by the deaf and voiceless community to be able to 
communicate with others, but the most commonly faced problem here is that everyone around may not be able 
to understand sign language. Written communication can be also be used but it is slow as compared to face-toface communication. 
In case emergency situations its more efficient to use sign language than written communication therefore, many sign languages were created in different countries of world.
American Sign Language was created in 1817 for deaf students. The main goal was to represent the letter and 
structure of the English language using hands, so that deaf students can use English. Until 1835, ASL was used 
as a language of instruction and student communication in schools for the deaf. Sooner the use of Sign Language 
spread throughout the world.
To solve this problem, we can use a custom Convolution Neural Networks (CNN) model to recognize hand 
gestures. Sign language recognition is a collaborative research field that includes natural language processing, 
computer vision, pattern matching, and linguistics. Its goal is to compile various methods and algorithms in 
order to identify already created signs and perceive their meaning.
